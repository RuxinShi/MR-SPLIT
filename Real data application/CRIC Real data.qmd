---
title: CRIC Real data
author: 
  - name: Ruxin Shi
    orcid: 0009-0001-9483-6444
    email: shiruxin@msu.edu
    affiliations: 
      - name: Michigan State University, Statistics and Probability
params:
  SourceDir: "Application on real data/"
  SourceFile: "CRIC Real data.qmd"
  LogFile: "CRIC Real data.html"
date: now
date-modified: last-modified
date-format: YYYY-MM-DD HH:mm:ss z
format: 
  html:
    toc: true
    toc-depth: 4
    toc-location: left
    number-sections: true
    number-depth: 3
    code-fold: true
    code-tools: true
    code-line-numbers: false
    embed-resources: true 
    anchor-sections: true
execute:
  eval: true
  echo: fenced
  output: true
  message: true
  warning: false
  error: true
  include: true
knitr:
  opts_chunk: 
    message: true 
    cfsize: "scriptsize"
---

```{=tex}
\begin{comment}
# Hidden: Notes for User
This script makes use of the LaTeX `verbatim` package's `\comment` command to
build in hidden headings and text that are here for the team preparing the
report but will be omitted from the knitted PDF output file. This makes it
easier to put important comments directly in the file while still creating fully
formatted output that only shows the desired content. So, text inside a comment
block will be omitted from the PDF output.

We can also use code chunks with chunk options such as `#| include: false`, 
`#| echo: false`, `#| message: false`, `#| warning: false` and so on to 
precisely control what R output shows up in the final PDF file. Thus, a script 
file can both serve as process documentation and efficiently generate the final 
version of a report output by applying the reproducible research and literate
programming concepts and tools. 

The `\lfoot` command just below sets the left footer to match the script's 
`LofgFile` parameter value, which we can pass along when rendering the script. 
Ideally it would be in the YAML `include-in-header:` with other pieces, but
I can't get inline code to work if I do it that way. This is the only way I 
could get the filename-based footer to work. 

The LaTeX `placeins` package provides the `\FloatBarrier` command. Using that 
before section headings help keep the figures and tables in their respective 
sections. 
\end{comment}
```
\lfoot{\texttt{\small \detokenize{`r params$LogFile`}}}

\FloatBarrier

# Purpose

This file provides results of MR-SPLIT being applied on the dataset CRIC

# Setting

## Define Global Options

Global R chunk options are defined in the YAML header but local chunk options will over-ride global options. We can temporarily disable an individual chunk by inserting `#| eval = FALSE` on a line at the top of the chunk. The method for creating a `cfsize` option that controls font size in code chunks and their text output is based on an answer to a question posted on [stackoverflow.com](https://stackoverflow.com/a/46526740).

```{r}
#| label: global-options
#| cfsize: footnotesize

# Create a custom chunk hook/option for controlling font size in chunk & output.
# Global value for this is set in YAML header. 
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$cfsize != "normalsize", 
         paste0("\n \\", options$cfsize,"\n\n", x, "\n\n \\normalsize"), 
         x)
  })
```

## Load Packages

Load R packages that we need to get additional functions.

```{r}
#| label: load-packages

library(ivreg)
library(MASS)
library(ggplot2)
library(hdi)
library(glmnet)
library(dplyr)
library(qqman)
library(screening)
library(foreach)
library(doParallel)
library(kableExtra)
library(quarto)           # for quarto_version()
library(gridExtra)
library(genetics)
library(SNPRelate)
```

\FloatBarrier

# Application Results

## Exposure: EGFR, Outcome: ATRH

### GENE DATA: gene selected to have partial pvalue\<0.01 with the exposure

```{r eval=FALSE}
gene=read.table("../../msu/research/CRIC/derived data/onlywhite_gene_p01.txt",header = TRUE)
ncol(gene)
nrow(gene)
#NA
I=length(gene[1,])
for(j in 1:I){
    gene[,j]=as.factor(gene[,j])
    a=length(gene[is.na(gene[,j]),j])
    if(a!=0){
      if(is.factor(gene[1,j])==TRUE){
        k=summary(gene[,j])
        q=as.factor(names(k)[1:(length(k)-1)])
        gene[is.na(gene[,j]),j]=sample(q,a,replace = TRUE,prob=k[1:(length(k)-1)]/sum(k[1:(length(k)-1)]))
      }
    }
    gene[,j]=as.numeric(as.character(gene[,j]))
}

A=cor(gene)
need=NULL
for(i in 1:ncol(gene)){
  if(sum(abs(A[,i])>0.8)>=2)need=c(need,i)
}
gene_need_LD=gene[,need]
gene_LD=gene_need_LD
i=1
while(i<ncol(gene_LD)){
      snps_to_remove=apply(as.matrix(gene_LD[,(i+1):ncol(gene_LD)]),2,function(x)filter_ld(x,gene_LD[,i]))
      if((i+1)==ncol(gene_LD)){
        if(snps_to_remove==1)gene_LD=gene_LD[,1:i]
      }
      if((i+1)<ncol(gene_LD)){
        gene_LD_new=gene_LD[,(i+1):ncol(gene_LD)][,!snps_to_remove]
        gene_LD=cbind(gene_LD[,1:i], gene_LD_new)
      }
      i=i+1
      print(c("i"=i,ncol(gene_LD)))
}
Equal=makeequal(colnames(gene_need_LD),colnames(gene_LD))
gene=gene[,-need[-Equal[[1]]]]
write.table(gene,"../../msu/research/CRIC/derived data/onlywhite_gene_p01_LD.txt")
```

```{r}
gene=read.table("../../msu/research/CRIC/derived data/onlywhite_gene_p01_LD.txt",header = TRUE)
ncol(gene)
nrow(gene)

```

### Exposure: EGFR and Outcome: ATRH

```{r}
makeequal <- function(A, B) {
  a=NULL
  b=NULL
  i <- 1
  q=1
  while (i <= length(A)) {
    B_id=grep(A[i],B)
    if (length(B_id)>0) {
      a[q]=i
      b[q]=B_id
      q=q+1
    }
    i=i+1
  }
  return(list(a,b))
}
filter_ld <- function(data1,data2) {
  ld_result <- LD(as.genotype.allele.count(data1), as.genotype.allele.count(data2))
  if (ld_result$`R^2` > r2_threshold) {
    return(1)
  }
  if (ld_result$`R^2` <= r2_threshold) {
    return(0)
  }
}

```

```{r}
cova=read.table("../../msu/research/CRIC/derived data/white_covariates.txt",header = TRUE)
Data=read.table("../../msu/research/CRIC/derived data/all data(dummy).txt",header = TRUE)
whiteID=read.table("../../msu/research/CRIC/derived data/whiteID.txt")
onlywhite=makeequal(as.character(Data[,1]),as.character(whiteID))
Data=Data[onlywhite[[1]],]
X=Data[,4]#EGFR,continuous
Y=Data[,2]#ATRH,binary
hist(X,main = "histogram of EGFR")
A=summary(as.factor(Y))
kable(A, "html", col.names = c("Number"),caption = "Summary of ATRH") %>%
  kable_styling()
boxplot(X~Y,xlab = "ATRH",ylab = "EGFR")
```

### MR-SPLIT

Split times: 50

```{r eval=FALSE}
N=length(X)
split.time=50
set.seed(100)
kk=2
weightcal=function(weight){
  len=length(weight)
  a=(weight>=0)
  b=abs(weight)/sum(abs(weight))
  c=NULL
  for(i in 1:len){
    if(a[i])c[i]=b[i]
    if(!a[i])c[i]=-1*b[i]
  }
  return(c)
}
point.est1=matrix(0,nrow=split.time,ncol=4)
colnames(point.est1)=c("Estimate","Std.error","t value","P.value")
num.major=NULL
num.weak=NULL
set.seed(2)
for(j in 1:split.time){
  #split sample
  selected=list()
  unselected=1:N
  n=sample(unselected,size=N/kk,replace = FALSE)
  selected[[1]]=n
  selected[[2]]=unselected[-n]
  
  selectIV=list()
  for(p in 1:kk){
    n=selected[[p]]
    fit=screening(gene[-n,],X[-n],method = "sis")
    selectIV[[p]]=gene[,fit$screen]
  }
  
  #LASSO
  weights=list()
  for(p in 1:kk){
    n=selected[[p]]
    #select IVs 
    lambda=cv.glmnet(as.matrix(selectIV[[p]][-n,]),X[-n],alpha=1)$lambda.min
    lasso=glmnet(selectIV[[p]][-n,],X[-n],lambda=lambda)
    #coef of all IVs
    a=coef(lasso)[-1,]
    weights[[p]]=a[a!=0]
    #selected IVs
    selectIV[[p]]=selectIV[[p]][,a!=0]
  }
  length(selectIV[[1]][1,])
  #211
  length(selectIV[[2]][1,])
  #254
  
        #select major and weak based on partial F statistics
            partialF=list()
            for(p in 1:kk){
              n=selected[[p]]
              full=lm(X[-n]~.,data=selectIV[[p]][-n,])
              Fs=NULL
              if(length(selectIV[[p]])==1){
                Fs=summary(full)$fstat[1]
              }
              if(length(selectIV[[p]])>1){
                for(q in 1:length(selectIV[[p]])){
                  reduced=lm(X[-n]~.,data=selectIV[[p]][-n,-q])
                  Fs[q]=anova(reduced,full)$F[2]
                }
              }
              partialF[[p]]=Fs
            }
            selectmajor=list()
            selectweak=list()
            for(p in 1:kk){
              selectmajor[[p]]=as.matrix(selectIV[[p]][,partialF[[p]]>=30])
              selectweak[[p]]=as.matrix(selectIV[[p]][,partialF[[p]]<30])
              num.major=c(num.major,length(selectmajor[[p]][1,]))
              num.weak=c(num.weak,length(selectweak[[p]][1,]))
            }
  
   #Get combineMajor
  combineMajor=list()
  for(p in 1:kk){
    n=selected[[p]]
    weakwei=weights[[p]][partialF[[p]]<30]
    weakwei=weightcal(weakwei)
    combineMajor[[p]]=cbind(selectmajor[[p]][n,],as.matrix(selectweak[[p]][n,])%*%weakwei)
  }
  #MAJOR
  hatX=NULL
  for(p in 1:kk){
    n=selected[[p]]
    fit=lm(X[n]~.,data=as.data.frame(combineMajor[[p]]))
    hatX=c(hatX,fit$fitted.values)
  }
  ord=c(selected[[1]],selected[[2]])
  fit1 <- glm(Y[ord]~hatX, family = binomial(link = "logit"))
  point.est1[j,]=summary(fit1)$coef[2,1:4]
  
}
write.table(point.est1,"results/egfr_atrh.txt",row.names = FALSE)
write.table(cbind(num.major,num.weak),"results/egfr_atrh_num_IVs.txt",row.names = FALSE)

```

```{r fig.height=4,fig.width=5}
MR_SPLIT=read.table("results/egfr_atrh.txt",header = TRUE)
hist(MR_SPLIT[,4],main=NULL,breaks = 20,ylim=c(0,50),xlab = "p-values out of 50 sample splits")
#abline(v = 0.05, col = "black", lty = 2)
legend("topright", legend = expression("combined p-value=" * 3.516 %*% 10^-5), col = "black", cex = 0.8, bty = "n")


T1=mean(tan((0.5-MR_SPLIT[,4])*pi))
p1=0.5-atan(T1)/pi
print(p1)
hist(MR_SPLIT[,1], breaks = 20, main = NULL, 
     xlab = expression("Causal estimates (" * hat(beta) * ") out of 50 sample splits."))

abline(v = mean(MR_SPLIT[,1]), col = "black", lty = 2)
legend("topright", legend = expression(hat(beta) == -0.5385), lty = 2, col = "black", cex = 0.8, bty = "n")
print(mean(MR_SPLIT[,1]))
```

### CFMR

```{r eval=FALSE}
N=length(X)

set.seed(2)
k=10
#CFMR
{
  #split sample
  selected=NULL
  unselected=1:N
  n=sample(unselected,size=N/k,replace = FALSE)
  selected=cbind(selected,n)
  for(p in 1:k){
    if(p<k){
      n=sample(unselected[-selected],size=N/k,replace = FALSE)
      selected=cbind(selected,n)
    }
  }
   
  selectIV=list()
  for(p in 1:k){
    n=selected[[p]]
    fit=screening(gene[-n,],X[-n],method = "sis")
    selectIV[[p]]=gene[,fit$screen]
  }
  #LASSO
  combineCFMR=NULL
  for(p in 1:k){
    n=selected[,p]
    #select IVs 
    lasso=cv.glmnet(as.matrix(selectIV[[p]][-n,]),X[-n],alpha=1)
    #coef of all IVs
    combineCFMR=c(combineCFMR,predict(lasso,as.matrix(selectIV[[p]][n,]), s = "lambda.min"))
  }
  
  ord=c(selected)
  #CFMR
   first1=lm(X[ord]~combineCFMR)
    fit1=glm(Y[ord]~first1$fitted.values,family = binomial(link = "logit"))
  CFMR=c(summary(fit1)$coef[2,c(1:4)])
}
write.table(CFMR,"results/CFMR_egfr_atrh.txt",row.names = FALSE)
```

```{r}
CFMR=read.table("results/CFMR_egfr_atrh.txt",header = TRUE)
rownames(CFMR)=c("Estimate","Std. Error","t value","Pr(>|t|)")
kable(round(CFMR,4), "html", col.names = c("CFMR"),caption = "Results of CFMR") %>%
  kable_styling()
```

### 2SLS

```{r}
times=1
set.seed(100)
#TSLS
point.est1=matrix(NA,ncol=4,nrow=times)

#NA
I=length(gene[1,])
set.seed(2)
for(j in 1:I){
    gene[,j]=as.factor(gene[,j])
    a=length(gene[is.na(gene[,j]),j])
    if(a!=0){
      if(is.factor(gene[1,j])==TRUE){
        k=summary(gene[,j])
        q=as.factor(names(k)[1:(length(k)-1)])
        gene[is.na(gene[,j]),j]=sample(q,a,replace = TRUE,prob=k[1:(length(k)-1)]/sum(k[1:(length(k)-1)]))
      }
    }
    gene[,j]=as.numeric(as.character(gene[,j]))
}

for(t in 1:times){
  #TSLS
  #select IVs using SIS
  selectIV=NULL
  fit=screening(gene,X,method = "sis")
  selectIV=gene[,fit$screen]
  #LASSO
  #select IVs 
  lambda=cv.glmnet(as.matrix(selectIV),X,alpha=1)$lambda.min
  lasso=glmnet(selectIV,X,lambda=lambda)
  #coef of all IVs
  a=coef(lasso)[-1,]
  #selected IVs
  selectIV=selectIV[,a!=0]
  first1=lm(X~as.matrix(selectIV))
  fit1=glm(Y~first1$fitted.values,family = binomial(link = "logit"))
  point.est1[t,]=summary(fit1)$coef[2,1:4]
}

colnames(point.est1)=c("Estimate","Std.error","t value","P.value")
kable(point.est1, "html", caption = "Summary of 2SLS") %>%
  kable_styling()
```

### Summary

```{r}
A=matrix(0,nrow=3,ncol=2)
rownames(A)=c("MR-SPLIT","CFMR","2SLS")
colnames(A)=c("Estimates","Pvalue")
A[1,]=c(mean(MR_SPLIT[,1]),p1)
A[2,]=c(CFMR[1,1],CFMR[4,1])
A[3,]=point.est1[1,c(1,4)]
kable(A, "html", caption = "Comparison between methods") %>%
  kable_styling()
```

## Exposure: uACR, Outcome: ATRH

### Exposure: uACR and Outcome: ATRH

```{r}
makeequal <- function(A, B) {
  a=NULL
  b=NULL
  i <- 1
  q=1
  while (i <= length(A)) {
    B_id=grep(A[i],B)
    if (length(B_id)>0) {
      a[q]=i
      b[q]=B_id
      q=q+1
    }
    i=i+1
  }
  return(list(a,b))
}
r2_threshold=0.8
filter_ld <- function(data1,data2) {
  ld_result <- LD(as.genotype.allele.count(data1), as.genotype.allele.count(data2))
  if (ld_result$`R^2` > r2_threshold) {
    return(1)
  }
  if (ld_result$`R^2` <= r2_threshold) {
    return(0)
  }
}

```

```{r eval=FALSE}
library(sas7bdat)
visit=read.sas7bdat("../../msu/research/CRIC/derived data/visitlevel.sas7bdat")
X1=cbind(visit$PID,visit$UALBUMIN24H)
X2=cbind(visit$PID,visit$UCREATININE24H)
base=read.csv("derived data/baseline.csv")
Y=base[,c(2,27)]#others are all included in v3

Data=cbind(X1,X2[,2])
Data=Data[Data[,2]!="NaN",]
Data=Data[Data[,3]!="NaN",]
colnames(Data)=c("PID","ALBUMIN","CREATININE")

whiteID=read.table("derived data/whiteID.txt")
onlywhite=makeequal(as.character(as.numeric(Data[,1])),as.character(whiteID[,1]))
Data=Data[onlywhite[[1]],]
onlywhite=makeequal(as.character(Y[,1]),as.character((Data[,1])))
Y=Y[onlywhite[[1]],]

write.table(cbind(Data,Y[,2]),"../../msu/research/CRIC/derived data/uACR and ATRH_white.txt",row.names = FALSE)
```

```{r}
Data=read.table("../../msu/research/CRIC/derived data/uACR and ATRH_white.txt",header = TRUE)
X=Data[,2]/Data[,3]#uACR
Y=Data[,4]#ATRH
hist(X,main = "histogram of uACR")
boxplot(X~Y,xlab = "ATRH",ylab = "uACR")

log_X=log(X)
hist(log_X,main = "histogram of log_uACR")
A=summary(as.factor(Y))
kable(A, "html", col.names = c("Number"),caption = "Summary of ATRH") %>%
  kable_styling()
boxplot(log_X~Y,xlab = "ATRH",ylab = "log_uACR")
```

So I use log(uACR) as the exposure.

### GENE DATA: gene selected to have partial pvalue\<0.01 with the exposure

```{r eval=FALSE}
library(trio)
library(foreach)
library(doParallel)
num <- c(1:24)
gene_select2=NA
cl <- makeCluster(14)
registerDoParallel(cl)
for(i in num){
  path <- paste0("derived data/chr",i, ".raw")
  gene <- read.pedfile(file = path)[,-c(2:6)]
  gene=gene[-1,]
  onlywhite=makeequal(as.character(gene[,1]),as.character(Data$PID))
  gene=gene[onlywhite[[1]],]
  gene=gene[,-1]
  
  I=length(gene[1,])
  pvalue=NULL

  results=foreach(j=1:I, .combine=rbind)%dopar%{
    #NA
    gene[,j]=as.factor(gene[,j])
    a=length(gene[is.na(gene[,j]),j])
    if(a!=0){
      if(is.factor(gene[1,j])==TRUE){
        k=summary(gene[,j])
        q=as.factor(names(k)[1:(length(k)-1)])
        gene[is.na(gene[,j]),j]=sample(q,a,replace = TRUE,prob=k[1:(length(k)-1)]/sum(k[1:(length(k)-1)]))
      }
    }
    #pvalue
    gene[,j]=as.numeric(as.character(gene[,j]))
    fit=lm(X~gene[,j])
    pvalue=summary(fit)$coef[2,4]
    return(pvalue)
  }
  
  colnames(gene)=paste(i,colnames(gene),seq="")
  gene_select2=cbind(gene_select2,gene[,results<=0.01])
  #gene_select3=cbind(gene_select3,gene[,pvalue<=0.001])
}
stopCluster(cl)
#p
write.table(gene_select2[,-1],"derived data/onlywhite_gene_p01_uACR.txt",row.names = FALSE)
```

```{r eval=FALSE}
gene=read.table("../../msu/research/CRIC/derived data/onlywhite_gene_p01_uACR.txt",header = TRUE)
ncol(gene)
nrow(gene)
#NA
I=length(gene[1,])
for(j in 1:I){
    gene[,j]=as.factor(gene[,j])
    a=length(gene[is.na(gene[,j]),j])
    if(a!=0){
      if(is.factor(gene[1,j])==TRUE){
        k=summary(gene[,j])
        q=as.factor(names(k)[1:(length(k)-1)])
        gene[is.na(gene[,j]),j]=sample(q,a,replace = TRUE,prob=k[1:(length(k)-1)]/sum(k[1:(length(k)-1)]))
      }
    }
    gene[,j]=as.numeric(as.character(gene[,j]))
}

A=cor(gene)
need=NULL
for(i in 1:ncol(gene)){
  if(sum(abs(A[,i])>0.8)>=2)need=c(need,i)
}
gene_need_LD=gene[,need]
gene_LD=gene_need_LD
i=1
while(i<ncol(gene_LD)){
      snps_to_remove=apply(as.matrix(gene_LD[,(i+1):ncol(gene_LD)]),2,function(x)filter_ld(x,gene_LD[,i]))
      if((i+1)==ncol(gene_LD)){
        if(snps_to_remove==1)gene_LD=gene_LD[,1:i]
      }
      if((i+1)<ncol(gene_LD)){
        gene_LD_new=gene_LD[,(i+1):ncol(gene_LD)][,!snps_to_remove]
        gene_LD=cbind(gene_LD[,1:i], gene_LD_new)
      }
      i=i+1
      print(c("i"=i,ncol(gene_LD)))
}
Equal=makeequal(colnames(gene_need_LD),colnames(gene_LD))
gene=gene[,-need[-Equal[[1]]]]
write.table(gene,"../../msu/research/CRIC/derived data/onlywhite_gene_p01_uACR_LD.txt")
```

```{r}
gene=read.table("../../msu/research/CRIC/derived data/onlywhite_gene_p01_uACR_LD.txt",header = TRUE)
ncol(gene)
nrow(gene)

```

### MR-SPLIT

Split times: 50

```{r eval=FALSE}
X=log_X
N=length(X)
split.time=50
set.seed(100)
kk=2
weightcal=function(weight){
  len=length(weight)
  a=(weight>=0)
  b=abs(weight)/sum(abs(weight))
  c=NULL
  for(i in 1:len){
    if(a[i])c[i]=b[i]
    if(!a[i])c[i]=-1*b[i]
  }
  return(c)
}
point.est1=matrix(0,nrow=split.time,ncol=4)
colnames(point.est1)=c("Estimate","Std.error","t value","P.value")

set.seed(2)
num.major=NULL
num.weak=NULL
for(j in 1:split.time){
  #split sample
  selected=list()
  unselected=1:N
  n=sample(unselected,size=N/kk,replace = FALSE)
  selected[[1]]=n
  selected[[2]]=unselected[-n]
  
  selectIV=list()
  for(p in 1:kk){
    n=selected[[p]]
    fit=screening(gene[-n,],X[-n],method = "sis")
    selectIV[[p]]=gene[,fit$screen]
  }
  
  #LASSO
  weights=list()
  for(p in 1:kk){
    n=selected[[p]]
    #select IVs 
    lambda=cv.glmnet(as.matrix(selectIV[[p]][-n,]),X[-n],alpha=1)$lambda.min
    lasso=glmnet(selectIV[[p]][-n,],X[-n],lambda=lambda)
    #coef of all IVs
    a=coef(lasso)[-1,]
    weights[[p]]=a[a!=0]
    #selected IVs
    selectIV[[p]]=selectIV[[p]][,a!=0]
  }

   #select major and weak based on partial F statistics
            partialF=list()
            for(p in 1:kk){
              n=selected[[p]]
              full=lm(X[-n]~.,data=selectIV[[p]][-n,])
              Fs=NULL
              if(length(selectIV[[p]])==1){
                Fs=summary(full)$fstat[1]
              }
              if(length(selectIV[[p]])>1){
                for(q in 1:length(selectIV[[p]])){ reduced=lm(X[-n]~.,data=selectIV[[p]][-n,-q])
                  Fs[q]=anova(reduced,full)$F[2]
                }
              }
              partialF[[p]]=Fs
            }
            selectmajor=list()
            selectweak=list()
            for(p in 1:kk){
              selectmajor[[p]]=as.matrix(selectIV[[p]][,partialF[[p]]>=30])
              selectweak[[p]]=as.matrix(selectIV[[p]][,partialF[[p]]<30])
              num.major=c(num.major,length(selectmajor[[p]][1,]))
              num.weak=c(num.weak,length(selectweak[[p]][1,]))
            }

   #Get combineMajor
  
  combineMajor=list()
  for(p in 1:kk){
    n=selected[[p]]
    weakwei=weights[[p]][partialF[[p]]<30]
    weakwei=weightcal(weakwei)
    combineMajor[[p]]=cbind(selectmajor[[p]][n,],as.matrix(selectweak[[p]][n,])%*%weakwei)
  }
  #MAJOR
  hatX=NULL
  for(p in 1:kk){
    n=selected[[p]]
    fit=lm(X[n]~.,data=as.data.frame(combineMajor[[p]]))
    hatX=c(hatX,fit$fitted.values)
  }
  ord=c(selected[[1]],selected[[2]])
  fit1 <- glm(Y[ord]~hatX, family = binomial(link = "logit"))
  point.est1[j,]=summary(fit1)$coef[2,1:4]
  
}
write.table(point.est1,"results/uACR_atrh.txt",row.names = FALSE)
write.table(cbind(num.major,num.weak),"results/uACR_atrh_num_IV.txt",row.names = FALSE)
```

```{r fig.height=4,fig.width=5}
MR_SPLIT=read.table("results/uACR_atrh.txt",header = TRUE)
hist(MR_SPLIT[,4],xlab = "p-values out of 50 sample splits",breaks = 20,ylim=c(0,50),main=NULL)
#abline(v = 0.05, col = "black", lty = 2)
legend("topright", legend = expression("combined p-value=" * 2.593 %*% 10^-4),  col = "black", cex = 0.8, bty = "n")

T1=mean(tan((0.5-MR_SPLIT[,4])*pi))
p1=0.5-atan(T1)/pi
print(p1)
hist(MR_SPLIT[,1], breaks = 8,  xlab = expression("Causal estimates (" * hat(beta) * ") out of 50 sample splits."), main = NULL)
abline(v = mean(MR_SPLIT[,1]), col = "black", lty = 2)
legend("topright", legend = expression(hat(beta) == 0.1827), lty = 2, col = "black", cex = 0.8, bty = "n")
print(mean(MR_SPLIT[,1]))
```

### CFMR

```{r eval=FALSE}
X=log_X
N=length(X)
weightcal=function(weight){
  len=length(weight)
  a=(weight>=0)
  b=abs(weight)/sum(abs(weight))
  c=NULL
  for(i in 1:len){
    if(a[i])c[i]=b[i]
    if(!a[i])c[i]=-1*b[i]
  }
  return(c)
}

set.seed(2)
#CFMR
{
  #split sample
  selected=NULL
  unselected=1:N
  n=sample(unselected,size=N/k,replace = FALSE)
  selected=cbind(selected,n)
  for(p in 1:k){
    if(p<k){
      n=sample(unselected[-selected],size=N/k,replace = FALSE)
      selected=cbind(selected,n)
    }
  }
   selectIV=list()
  for(p in 1:k){
    n=selected[[p]]
    fit=screening(gene[-n,],X[-n],method = "sis")
    selectIV[[p]]=gene[,fit$screen]
  }
  #LASSO
  combineCFMR=NULL
  for(p in 1:k){
    n=selected[,p]
    #select IVs 
    lasso=cv.glmnet(as.matrix(selectIV[[p]][-n,]),X[-n],alpha=1)
    #coef of all IVs
    combineCFMR=c(combineCFMR,predict(lasso,as.matrix(selectIV[[p]][n,]), s = "lambda.min"))
  }
  
  ord=c(selected)
  #CFMR
   first1=lm(X[ord]~combineCFMR)
    fit1=glm(Y[ord]~first1$fitted.values,family = binomial(link = "logit"))
  CFMR=c(summary(fit1)$coef[2,c(1:4)])
}
write.table(CFMR,"results/CFMR_uACR.txt",row.names = FALSE)
```

```{r}
CFMR=read.table("results/CFMR_uACR.txt",header = TRUE)
rownames(CFMR)=c("Estimate","Std. Error","t value","Pr(>|t|)")
kable(round(CFMR,4), "html", col.names = c("CFMR"),caption = "Results of CFMR") %>%
  kable_styling()
```

### 2SLS and LIML

```{r}
times=1
set.seed(100)
#TSLS
point.est1=matrix(NA,ncol=4,nrow=times)

for(t in 1:times){
  #TSLS and LIML
  #select IVs using SIS
  selectIV=NULL
  fit=screening(gene,X,method = "sis")
  selectIV=gene[,fit$screen]
  #LASSO
  #select IVs 
  lambda=cv.glmnet(as.matrix(selectIV),X,alpha=1)$lambda.min
  lasso=glmnet(selectIV,X,lambda=lambda)
  #coef of all IVs
  a=coef(lasso)[-1,]
  #selected IVs
    first1=lm(X~as.matrix(selectIV))
  fit1=lm(Y~first1$fitted.values,family = binomial(link = "logit"))
  point.est1[t,]=summary(fit1)$coef[2,1:4]
  #fit1=ivmodel(Y=Y,D=X,Z=selectIV)
  
  #point.est2[t,]=c(fit1$LIML$point.est,fit1$LIML$std.err,fit1$LIML$test.stat.other,fit1$LIML$p.value)
}

colnames(point.est1)=c("Estimate","Std.error","t value","P.value")
#colnames(point.est2)=c("Estimate","Std.error","t value","P.value")
kable(point.est1, "html", caption = "Summary of 2SLS") %>%
  kable_styling()
#kable(point.est2, "html", caption = "Summary of LIML") %>%
#  kable_styling()
```

### Summary

```{r}
#A=matrix(0,nrow=4,ncol=2)
#rownames(A)=c("MR-SPLIT","CFMR","2SLS","LIML")
A=matrix(0,nrow=3,ncol=2)
rownames(A)=c("MR-SPLIT","CFMR","2SLS")
colnames(A)=c("Estimates","Pvalue")
A[1,]=c(mean(MR_SPLIT[,1]),p1)
A[2,]=c(CFMR[1,1],CFMR[4,1])
A[3,]=point.est1[1,c(1,4)]
#A[4,]=point.est2[1,c(1,4)]
kable(A, "html", caption = "Comparison between methods") %>%
  kable_styling()
```

# Software Information

This section documents information that is important for reproducibility. Most users will not need to read it. It is primarily here for use by the statistician on the team.

We used [R](https://www.r-project.org/) as our main computing environment and [Quarto](https://quarto.org/) scripts to enhance reproducibility. We used [RStudio](www.rstudio.org) as the editor to interface with R and Quarto.

-   Software chain: **qmd file \> RStudio \> Quarto \> R \> knitr \> md file \> Pandoc \> html file**.
-   Source file: **`r params$SourceFile`**
-   Output file: **`r params$LogFile`**
-   [Quarto `r quarto_version()`](https://quarto.org/) runs `*.qmd` files through [R](https://www.r-project.org/) and [knitr](https://yihui.org/knitr/) to produce `*.md` markdown files.
-   [Pandoc `r rmarkdown::pandoc_version()`](https://pandoc.org) converts markdown files (`*.md`) to other formats, including LaTeX (`*.tex`) and HTML (`*.html`) among others.

\FloatBarrier

## Versions

This document was generated using the following computational environment and dependencies:

```{r}
#| label: show-version
#| cfsize: scriptsize
#| echo: true

# Get R and R package version numbers in use.
devtools::session_info()
```

\FloatBarrier
